ü§ñ Treinamento e Compara√ß√£o de Modelos de Regress√£o
Este projeto demonstra o treinamento, avalia√ß√£o e compara√ß√£o de diferentes modelos de Machine Learning (Aprendizado de M√°quina) para uma tarefa de Regress√£o. O objetivo √© analisar o desempenho de cada algoritmo em um conjunto de dados sint√©tico.

üìÅ Conte√∫do do Reposit√≥rio
Trabalho treino machine learning.ipynb: O notebook principal contendo todo o c√≥digo, treinamento de modelos, an√°lise e visualiza√ß√µes.

üõ†Ô∏è Tecnologias Utilizadas
O projeto foi desenvolvido em Python e utiliza as seguintes bibliotecas:

scikit-learn (sklearn): Para implementa√ß√£o dos modelos de regress√£o (√Årvore de Decis√£o, K-Nearest Neighbors e Regress√£o Linear), gera√ß√£o de dados sint√©ticos (make_regression) e divis√£o de conjuntos de treino/teste.

matplotlib: Para visualiza√ß√µes gr√°ficas, incluindo a an√°lise do impacto de hiperpar√¢metros.

pandas: Para manipula√ß√£o de dados e exibi√ß√£o da tabela de resultados.

üß™ Modelos e M√©tricas de Avalia√ß√£o
Foram treinados e comparados tr√™s modelos de regress√£o:

Decision Tree Regressor (√Årvore de Decis√£o)

K-Nearest Neighbors Regressor (KNN)

Linear Regression (Regress√£o Linear)

O desempenho dos modelos foi avaliado usando as seguintes m√©tricas de regress√£o:

MSE (Mean Squared Error): Erro Quadr√°tico M√©dio.

MAE (Mean Absolute Error): Erro Absoluto M√©dio.

R¬≤ (R-squared ou Coeficiente de Determina√ß√£o): Indica a propor√ß√£o da vari√¢ncia na vari√°vel dependente que √© previs√≠vel a partir das vari√°veis independentes (quanto mais pr√≥ximo de 1, melhor).


Conclus√£o dos Resultados:

O modelo de Regress√£o Linear apresentou o melhor desempenho geral, com o menor MSE e o maior R¬≤ (0.634106).

A an√°lise de hiperpar√¢metros (como o max_depth na √Årvore de Decis√£o) foi crucial para ilustrar a famosa troca entre Vi√©s (Underfitting) e Vari√¢ncia (Overfitting).

Um modelo muito simples (alto Vi√©s) n√£o aprende os detalhes do conjunto de treino.

Um modelo excessivamente complexo (alta Vari√¢ncia) memoriza os dados de treino, falhando em dados novos (teste).

A otimiza√ß√£o de hiperpar√¢metros busca o ponto ideal onde o modelo √© complexo o suficiente para aprender o padr√£o, mas n√£o a ponto de confundir ru√≠do com informa√ß√£o.
